{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN THIS CELL\n",
    "#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('PySparkShell').getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://master:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://master:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fb258b1feb8>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'id'),\n",
       " (1, 'title'),\n",
       " (2, 'position'),\n",
       " (3, 'date'),\n",
       " (4, 'countryId'),\n",
       " (5, 'chartName'),\n",
       " (6, 'movement'),\n",
       " (7, 'streams')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charts = spark.read.parquet('files/charts.parquet')\n",
    "# charts = charts.toDF('id', 'title', 'position', 'date', 'countryId', 'chartName', 'movement', 'streams')\n",
    "charts.createOrReplaceTempView('charts')\n",
    "chartsRDD = sc.textFile('files/charts.csv').map(lambda line: line.split(','))\n",
    "\n",
    "list(enumerate(charts.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|sum(streams)|\n",
      "+------------+\n",
      "|  2324245979|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "    SELECT sum(streams) FROM charts\n",
    "    WHERE chartName=\"top200\" AND title=\"Shape of You\"\n",
    "''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2324245979"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = 1\n",
    "chartName = 5\n",
    "streams = 7\n",
    "\n",
    "(\n",
    "    chartsRDD\n",
    "     .filter(lambda x: x[chartName] == 'top200' and x[title] == 'Shape of You')\n",
    "     .map(lambda x: int(x[streams]))\n",
    "     .reduce(lambda x, y: x + y)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|chartName|     max(avgCount)|\n",
      "+---------+------------------+\n",
      "|   top200|  54.2463768115942|\n",
      "|  viral50|24.985507246376812|\n",
      "+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    charts\n",
    "     .filter(F.col('position') == 1)\n",
    "     .groupBy(['chartName', 'title'])\n",
    "     .count()\n",
    "     .withColumn('avgCount', F.col('count') / 69)\n",
    "     .groupBy('chartName')\n",
    "     .agg(F.max('avgCount'))\n",
    "     .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+------------------+\n",
      "|chartName|               title|        maxAvgTime|\n",
      "+---------+--------------------+------------------+\n",
      "|   top200|Chantaje (feat. M...|  54.2463768115942|\n",
      "|  viral50|           I See Red|24.985507246376812|\n",
      "+---------+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "    SELECT chartName, first(title) title, max(avgCount) maxAvgTime\n",
    "    FROM (\n",
    "        SELECT chartName, title, count(*)/69 avgCount\n",
    "        FROM charts\n",
    "        WHERE position=1\n",
    "        GROUP BY chartName, title\n",
    "    )\n",
    "    GROUP BY chartName\n",
    "''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('viral50', 'Calma - Remix', 24.985507246376812),\n",
       " ('top200', 'Shape of You', 54.2463768115942)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = 1\n",
    "position = 2\n",
    "chartName = 5\n",
    "\n",
    "(\n",
    "    chartsRDD\n",
    "     .filter(lambda x: x[position] == '1')\n",
    "     .map(lambda x: ((x[chartName], x[title]), 1))\n",
    "     .reduceByKey(lambda x, y: x + y)\n",
    "     .map(lambda x: (x[0][0], (x[0][1], x[1]/69)))\n",
    "     .reduceByKey(lambda x, y: x if x[1] > y[1] else y)\n",
    "     .map(lambda x: (x[0], *x[1]))\n",
    "     .collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "7e62cdb2fab5fb240ec6e260358bf63224313d17ebcaacec076aef54bb50eba1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
