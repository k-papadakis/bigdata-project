{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN THIS CELL\n",
    "#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('PySparkShell').getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://master:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://master:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fee83fadeb8>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import operator\n",
    "\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_date(s):\n",
    "    dt = datetime.datetime.strptime(s[:10], '%Y-%m-%d')\n",
    "    return dt.date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'songId'),\n",
       " (1, 'title'),\n",
       " (2, 'position'),\n",
       " (3, 'date'),\n",
       " (4, 'countryId'),\n",
       " (5, 'chartName'),\n",
       " (6, 'movement'),\n",
       " (7, 'streams')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charts = spark.read.parquet('files/charts.parquet')\n",
    "# charts = charts.toDF('id', 'title', 'position', 'date', 'countryId', 'chartName', 'movement', 'streams')\n",
    "charts.createOrReplaceTempView('charts')\n",
    "chartsRDD = sc.textFile('files/charts.csv').map(lambda line: line.split(','))\n",
    "\n",
    "list(enumerate(charts.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "songId = 0\n",
    "title = 1\n",
    "position = 2\n",
    "date = 3\n",
    "countryId = 4\n",
    "chartName = 5\n",
    "movement = 6\n",
    "streams = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'countryId'), (1, 'countryName')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regions = spark.read.parquet('files/regions.parquet')\n",
    "regions.createOrReplaceTempView('regions')\n",
    "regionsRDD = sc.textFile('files/regions.csv').map(lambda line: line.split(','))\n",
    "\n",
    "list(enumerate(regions.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'songId'), (1, 'artistId')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chart_artist_mapping = spark.read.parquet('files/chart_artist_mapping.parquet')\n",
    "chart_artist_mapping.createOrReplaceTempView('chart_artist_mapping')\n",
    "chart_artist_mappingRDD = sc.textFile('files/chart_artist_mapping.csv').map(lambda line: line.split(','))\n",
    "\n",
    "list(enumerate(chart_artist_mapping.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'artistId'), (1, 'artistName')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists = spark.read.parquet('files/artists.parquet')\n",
    "artists.createOrReplaceTempView('artists')\n",
    "artistsRDD = sc.textFile('files/artists.csv').map(lambda line: line.split(','))\n",
    "\n",
    "list(enumerate(artists.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|sum(streams)|\n",
      "+------------+\n",
      "|  2324245979|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "    SELECT sum(streams) FROM charts\n",
    "    WHERE chartName=\"top200\" AND title=\"Shape of You\"\n",
    "''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2324245979"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    chartsRDD\n",
    "     .filter(lambda x: x[chartName] == 'top200' and x[title] == 'Shape of You')\n",
    "     .map(lambda x: int(x[streams]))\n",
    "     .reduce(operator.add)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|chartName|     max(avgCount)|\n",
      "+---------+------------------+\n",
      "|   top200|  54.2463768115942|\n",
      "|  viral50|24.985507246376812|\n",
      "+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    charts\n",
    "     .filter(F.col('position') == 1)\n",
    "     .groupBy(['chartName', 'songId'])\n",
    "     .count()\n",
    "     .withColumn('avgCount', F.col('count') / 69)\n",
    "     .groupBy('chartName')\n",
    "     .agg(F.max('avgCount'))\n",
    "     .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+------------------+\n",
      "|chartName|               title|        maxAvgTime|\n",
      "+---------+--------------------+------------------+\n",
      "|   top200|         100 zhivota|  54.2463768115942|\n",
      "|  viral50|\"\"\"Was He Slow?\"\"...|24.985507246376812|\n",
      "+---------+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "    SELECT chartName, first(title) title, max(avgCount) maxAvgTime\n",
    "    FROM (\n",
    "        SELECT chartName, first(title) title, count(*)/69 avgCount\n",
    "        FROM charts\n",
    "        WHERE position=1\n",
    "        GROUP BY chartName, songId\n",
    "    )\n",
    "    GROUP BY chartName\n",
    "''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('viral50', 'Calma - Remix', 24.985507246376812),\n",
       " ('top200', 'Shape of You', 54.2463768115942)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    chartsRDD\n",
    "     .filter(lambda x: x[position] == '1')\n",
    "     .map(lambda x: ((x[chartName], x[title]), 1))\n",
    "     .reduceByKey(operator.add)\n",
    "     .map(lambda x: (x[0][0], (x[0][1], x[1]/69)))\n",
    "     .reduceByKey(lambda x, y: x if x[1] > y[1] else y)\n",
    "     .map(lambda x: (x[0], *x[1]))\n",
    "     .collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+-----------------+\n",
      "|year(date)|month(date)|avg(sum(streams))|\n",
      "+----------+-----------+-----------------+\n",
      "|      2017|          1|7618611.064516129|\n",
      "|      2017|          2|8876450.785714285|\n",
      "|      2017|          3| 8955476.41935484|\n",
      "+----------+-----------+-----------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    charts\n",
    "     .filter((F.col('position') == 1) & (F.col('chartName') == 'top200'))\n",
    "     .groupBy('date')\n",
    "     .agg(F.sum('streams'))\n",
    "     .groupBy([F.year('date'), F.month('date')])\n",
    "     .agg(F.mean('sum(streams)'))\n",
    "     .orderBy([F.year('date'), F.month('date')])\n",
    "     .show(3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2017, 1, 7618611.064516129),\n",
       " (2017, 2, 8876450.785714285),\n",
       " (2017, 3, 8955476.41935484)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    chartsRDD\n",
    "     .filter(lambda x: x[position] == '1' and x[chartName] == 'top200')\n",
    "     .map(lambda x: (parse_date(x[date]), int(x[streams])))\n",
    "     .reduceByKey(operator.add)\n",
    "     .map(lambda x: ((x[0].year, x[0].month), (x[1], 1)))\n",
    "     .reduceByKey(lambda x, y: (x[0] + y[0], x[1] + y[1]))\n",
    "     .sortByKey()\n",
    "     .map(lambda x:(x[0][0], x[0][1], x[1][0] / x[1][1]))\n",
    "     .take(3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+---------+--------+\n",
      "|year(date)|month(date)| streams1|count(1)|\n",
      "+----------+-----------+---------+--------+\n",
      "|      2017|          1|236176943|      31|\n",
      "|      2017|          2|248540622|      28|\n",
      "|      2017|          3|277619769|      31|\n",
      "+----------+-----------+---------+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "    SELECT year(date), month(date), sum(streamsDay) streams1, count(*)\n",
    "    FROM (\n",
    "        SELECT date, sum(streams) streamsDay\n",
    "        FROM charts\n",
    "        WHERE position = 1 AND chartName == \"top200\"\n",
    "        GROUP BY date\n",
    "    )\n",
    "    GROUP BY year(date), month(date)\n",
    "    ORDER BY year(date), month(date)\n",
    "''').show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+--------------------+--------+\n",
      "|countryName|songId|               title|maxCount|\n",
      "+-----------+------+--------------------+--------+\n",
      "|    Andorra| 55526|Friday (feat. Muf...|     251|\n",
      "|  Argentina| 35851|        Dance Monkey|     253|\n",
      "|  Australia| 35851|        Dance Monkey|     217|\n",
      "+-----------+------+--------------------+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "    SELECT countryName, songId songId, title, maxCount\n",
    "    FROM (\n",
    "        SELECT countryId, songId, title, cnt, \n",
    "            max(cnt) OVER (PARTITION BY countryId) AS maxCount \n",
    "        FROM (\n",
    "            SELECT countryId, songId, first(title) title, count(*) cnt\n",
    "            FROM charts\n",
    "            WHERE chartName = \"viral50\"\n",
    "            GROUP BY countryId, songId\n",
    "        )\n",
    "    ) a\n",
    "    LEFT JOIN regions\n",
    "    ON a.countryId = regions.countryId\n",
    "    WHERE cnt = maxCount\n",
    "    ORDER BY countryName, title\n",
    "''').show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Andorra', '55526', 'Friday (feat. Mufasa;Hypeman) - Dopamine Re-Edit', 251),\n",
       " ('Argentina', '35851', 'Dance Monkey', 253),\n",
       " ('Australia', '35851', 'Dance Monkey', 217)]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (countryId, songId), (title, count)\n",
    "counts = (\n",
    "    chartsRDD\n",
    "     .filter(lambda x: x[chartName] == 'viral50')\n",
    "     .map(lambda x: ((x[countryId], x[songId]), (x[title], 1)))\n",
    "     .reduceByKey(lambda x, y: (x[0], x[1] + y[1]))\n",
    "     .map(lambda x: (x[0][0], (x[0][1], *x[1])))\n",
    ")\n",
    "\n",
    "# countryId, maxCount\n",
    "maxCounts = (\n",
    "    counts\n",
    "     .map(lambda x: (x[0], x[1][2]))\n",
    "     .reduceByKey(max)\n",
    ")\n",
    "\n",
    "# Joining now because both tables are tiny and of equal index\n",
    "\n",
    "# countryId, (countryName, countryId)\n",
    "maxCountsNamed = regionsRDD.join(maxCounts)\n",
    "\n",
    "q4 = (\n",
    "    counts\n",
    "     .join(maxCountsNamed)\n",
    "     .filter(lambda x: x[1][0][2] == x[1][1][1])\n",
    "     .map(lambda x: (x[1][1][0], x[1][0][0], x[1][0][1], x[1][1][1]))\n",
    "     .sortBy(lambda x: (x[0], x[1]))\n",
    ")\n",
    "\n",
    "q4.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------+--------------------+\n",
      "|  yr|    artistName|       maxAvgStreams|\n",
      "+----+--------------+--------------------+\n",
      "|2017|    Ed Sheeran|6.2263262666666664E7|\n",
      "|2018|   Post Malone| 6.812695868115942E7|\n",
      "|2019|   Post Malone|6.6283253927536234E7|\n",
      "|2020|     Bad Bunny| 7.794363488405797E7|\n",
      "|2021|Olivia Rodrigo| 6.446307111594203E7|\n",
      "+----+--------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "    SELECT yr, artistName, maxAvgStreams\n",
    "    FROM (\n",
    "        SELECT yr, artistId, avgStreams,\n",
    "            max(avgStreams) OVER (PARTITION BY yr) AS maxAvgStreams \n",
    "        FROM (\n",
    "            SELECT year(date) yr, artistId, sum(streams)/69 avgStreams\n",
    "            FROM charts\n",
    "            JOIN chart_artist_mapping\n",
    "            ON charts.songId = chart_artist_mapping.songId\n",
    "            WHERE chartName = \"top200\"\n",
    "            GROUP BY year(date), artistId\n",
    "        )\n",
    "    ) a\n",
    "    JOIN artists\n",
    "    ON a.artistId = artists.artistId\n",
    "    WHERE avgStreams = maxAvgStreams\n",
    "    ORDER BY yr\n",
    "''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2017, 'Ed Sheeran', 62263262.66666655),\n",
       " (2018, 'Post Malone', 68126958.68115947),\n",
       " (2020, 'Bad Bunny', 77943634.88405786),\n",
       " (2021, 'Olivia Rodrigo', 64463071.11594206)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (year, artistId), avgStreams\n",
    "\n",
    "avgStreams = (\n",
    "    chartsRDD\n",
    "     .filter(lambda x: x[chartName] == 'top200')\n",
    "     .map(lambda x: (x[songId], (parse_date(x[date]).year, int(x[streams]))))\n",
    "     .join(chart_artist_mappingRDD)  # songId, ((year, streams), artistId)\n",
    "     .map(lambda x: ((x[1][0][0], x[1][1]), x[1][0][1]/69))  # (year, artistId), streams\n",
    "     .reduceByKey(operator.add)\n",
    ")\n",
    "\n",
    "# year, maxAvgStreams\n",
    "maxAvgStreams = (\n",
    "    avgStreams\n",
    "     .map(lambda x: (x[0][0], x[1]))\n",
    "     .reduceByKey(max)\n",
    ")\n",
    "\n",
    "# (year, artistName, maxAvgStreams)\n",
    "q5 = (\n",
    "    avgStreams\n",
    "     .map(lambda x: (x[1], x[0]))  # avgStreams, (year, artistId)\n",
    "     .join(maxAvgStreams.map(lambda x: (x[1], None))) # avgStreams, ((year, artistId), None)\n",
    "     .map(lambda x: (x[1][0][1], (x[1][0][0], x[0])))  # artistId, (year, maxAvgStreams)\n",
    "     .join(artistsRDD)  # artistId, ((year, maxAvgStreams), artistName)\n",
    "     .map(lambda x: (x[1][0][0], x[1][1], x[1][0][1]))  # (year, artistName, maxAvgStreams)\n",
    "     .sortBy(lambda x: (x[0], x[1]))\n",
    ")\n",
    "\n",
    "q5.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "7e62cdb2fab5fb240ec6e260358bf63224313d17ebcaacec076aef54bb50eba1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
