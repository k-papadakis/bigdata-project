{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN THIS CELL\n",
    "#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('PySparkShell').getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!#!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://master:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://master:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fa87d634eb8>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'id'),\n",
       " (1, 'title'),\n",
       " (2, 'position'),\n",
       " (3, 'date'),\n",
       " (4, 'countryId'),\n",
       " (5, 'chartName'),\n",
       " (6, 'movement'),\n",
       " (7, 'streams')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charts = spark.read.parquet('files/charts.parquet')\n",
    "# charts = charts.toDF('id', 'title', 'position', 'date', 'countryId', 'chartName', 'movement', 'streams')\n",
    "charts.createOrReplaceTempView('charts')\n",
    "chartsRDD = sc.textFile('files/charts.csv').map(lambda line: line.split(','))\n",
    "\n",
    "list(enumerate(charts.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'id'), (1, 'countryName')]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regions = spark.read.parquet('files/regions.parquet')\n",
    "regions.createOrReplaceTempView('regions')\n",
    "regionsRDD = sc.textFile('files/regions.csv').map(lambda line: line.split(','))\n",
    "\n",
    "list(enumerate(regions.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|sum(streams)|\n",
      "+------------+\n",
      "|  2324245979|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "    SELECT sum(streams) FROM charts\n",
    "    WHERE chartName=\"top200\" AND title=\"Shape of You\"\n",
    "''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2324245979"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = 1\n",
    "chartName = 5\n",
    "streams = 7\n",
    "\n",
    "(\n",
    "    chartsRDD\n",
    "     .filter(lambda x: x[chartName] == 'top200' and x[title] == 'Shape of You')\n",
    "     .map(lambda x: int(x[streams]))\n",
    "     .reduce(lambda x, y: x + y)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|chartName|     max(avgCount)|\n",
      "+---------+------------------+\n",
      "|   top200|  54.2463768115942|\n",
      "|  viral50|24.985507246376812|\n",
      "+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    charts\n",
    "     .filter(F.col('position') == 1)\n",
    "     .groupBy(['chartName', 'id'])\n",
    "     .count()\n",
    "     .withColumn('avgCount', F.col('count') / 69)\n",
    "     .groupBy('chartName')\n",
    "     .agg(F.max('avgCount'))\n",
    "     .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------+------------------+\n",
      "|chartName|           title|        maxAvgTime|\n",
      "+---------+----------------+------------------+\n",
      "|   top200|            Burn|  54.2463768115942|\n",
      "|  viral50|A Million Dreams|24.985507246376812|\n",
      "+---------+----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "    SELECT chartName, first(title) title, max(avgCount) maxAvgTime\n",
    "    FROM (\n",
    "        SELECT chartName, first(title) title, count(*)/69 avgCount\n",
    "        FROM charts\n",
    "        WHERE position=1\n",
    "        GROUP BY chartName, id\n",
    "    )\n",
    "    GROUP BY chartName\n",
    "''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('viral50', 'Calma - Remix', 24.985507246376812),\n",
       " ('top200', 'Shape of You', 54.2463768115942)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = 1\n",
    "position = 2\n",
    "chartName = 5\n",
    "\n",
    "(\n",
    "    chartsRDD\n",
    "     .filter(lambda x: x[position] == '1')\n",
    "     .map(lambda x: ((x[chartName], x[title]), 1))\n",
    "     .reduceByKey(lambda x, y: x + y)\n",
    "     .map(lambda x: (x[0][0], (x[0][1], x[1]/69)))\n",
    "     .reduceByKey(lambda x, y: x if x[1] > y[1] else y)\n",
    "     .map(lambda x: (x[0], *x[1]))\n",
    "     .collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+-----------------+\n",
      "|year(date)|month(date)|avg(sum(streams))|\n",
      "+----------+-----------+-----------------+\n",
      "|      2017|          1|7618611.064516129|\n",
      "|      2017|          2|8876450.785714285|\n",
      "|      2017|          3| 8955476.41935484|\n",
      "+----------+-----------+-----------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    charts\n",
    "     .filter((F.col('position') == 1) & (F.col('chartName') == 'top200'))\n",
    "     .groupBy('date')\n",
    "     .agg(F.sum('streams'))\n",
    "     .groupBy([F.year('date'), F.month('date')])\n",
    "     .agg(F.mean('sum(streams)'))\n",
    "     .orderBy([F.year('date'), F.month('date')])\n",
    "     .show(3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1607',\n",
       "  '+',\n",
       "  '9',\n",
       "  '2020-01-13T00:00:00.000+02:00',\n",
       "  '46',\n",
       "  'viral50',\n",
       "  'NEW_ENTRY',\n",
       "  '\"\"']]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chartsRDD.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'id'),\n",
       " (1, 'title'),\n",
       " (2, 'position'),\n",
       " (3, 'date'),\n",
       " (4, 'countryId'),\n",
       " (5, 'chartName'),\n",
       " (6, 'movement'),\n",
       " (7, 'streams')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate(charts.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_date(s):\n",
    "    dt = datetime.datetime.strptime(s[:10], '%Y-%m-%d')\n",
    "    return dt.date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2017, 1, 7618611.064516129),\n",
       " (2017, 2, 8876450.785714285),\n",
       " (2017, 3, 8955476.41935484)]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position = 2\n",
    "date = 3\n",
    "chartName = 5\n",
    "streams = 7\n",
    "\n",
    "(\n",
    "    chartsRDD\n",
    "     .filter(lambda x: x[position] == '1' and x[chartName] == 'top200')\n",
    "     .map(lambda x: (parse_date(x[date]), int(x[streams])))\n",
    "     .reduceByKey(lambda x, y: x + y)\n",
    "     .map(lambda x: ((x[0].year, x[0].month), (x[1], 1)))\n",
    "     .reduceByKey(lambda x, y: (x[0] + y[0], x[1] + y[1]))\n",
    "     .sortByKey()\n",
    "     .map(lambda x:(x[0][0], x[0][1], x[1][0] / x[1][1]))\n",
    "     .take(3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+---------+--------+\n",
      "|year(date)|month(date)| streams1|count(1)|\n",
      "+----------+-----------+---------+--------+\n",
      "|      2017|          1|236176943|      31|\n",
      "|      2017|          2|248540622|      28|\n",
      "|      2017|          3|277619769|      31|\n",
      "+----------+-----------+---------+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "    SELECT year(date), month(date), sum(streamsDay) streams1, count(*)\n",
    "    FROM (\n",
    "        SELECT date, sum(streams) streamsDay\n",
    "        FROM charts\n",
    "        WHERE position = 1 AND chartName == \"top200\"\n",
    "        GROUP BY date\n",
    "    )\n",
    "    GROUP BY year(date), month(date)\n",
    "    ORDER BY year(date), month(date)\n",
    "''').show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+--------------------+--------+\n",
      "|countryName|songId|               title|maxCount|\n",
      "+-----------+------+--------------------+--------+\n",
      "|    Andorra| 55526|Friday (feat. Muf...|     251|\n",
      "|  Argentina| 35851|        Dance Monkey|     253|\n",
      "|  Australia| 35851|        Dance Monkey|     217|\n",
      "+-----------+------+--------------------+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "    SELECT countryName, songId songId, title, maxCount\n",
    "    FROM (\n",
    "        SELECT countryId, songId, title, cnt, \n",
    "            max(cnt) OVER (PARTITION BY countryId) AS maxCount \n",
    "        FROM (\n",
    "            SELECT countryId, id songId, first(title) title, count(*) cnt\n",
    "            FROM charts\n",
    "            WHERE chartName = \"viral50\"\n",
    "            GROUP BY countryId, id\n",
    "        )\n",
    "    )\n",
    "    LEFT JOIN regions\n",
    "    ON countryId = regions.id\n",
    "    WHERE cnt = maxCount\n",
    "    ORDER BY countryName, title\n",
    "''').show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Andorra', '55526', 'Friday (feat. Mufasa;Hypeman) - Dopamine Re-Edit', 251),\n",
       " ('Argentina', '35851', 'Dance Monkey', 253),\n",
       " ('Australia', '35851', 'Dance Monkey', 217)]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songId = 0\n",
    "title = 1\n",
    "countryId = 4\n",
    "chartName = 5\n",
    "\n",
    "# (countryId, songId), (title, count)\n",
    "counts = (\n",
    "    chartsRDD\n",
    "     .filter(lambda x: x[chartName] == 'viral50')\n",
    "     .map(lambda x: ((x[countryId], x[songId]), (x[title], 1)))\n",
    "     .reduceByKey(lambda x, y: (x[0], x[1] + y[1]))\n",
    "     .map(lambda x: (x[0][0], (x[0][1], *x[1])))\n",
    ")\n",
    "\n",
    "# countryId, maxCount\n",
    "max_counts = (\n",
    "    counts\n",
    "     .map(lambda x: (x[0], x[1][2]))\n",
    "     .reduceByKey(max)\n",
    "     .sortByKey()\n",
    ")\n",
    "\n",
    "# Joining now because both tables are tiny and of equal index\n",
    "\n",
    "# countryId, (countryName, countryId)\n",
    "max_counts_named = regionsRDD.join(max_counts)\n",
    "\n",
    "q4 = (\n",
    "    counts\n",
    "     .join(max_counts_named)\n",
    "     .filter(lambda x: x[1][0][2] == x[1][1][1])\n",
    "     .map(lambda x: (x[1][1][0], x[1][0][0], x[1][0][1], x[1][1][1]))\n",
    "     .sortBy(lambda x: (x[0], x[1]))\n",
    ")\n",
    "\n",
    "q4.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "7e62cdb2fab5fb240ec6e260358bf63224313d17ebcaacec076aef54bb50eba1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
